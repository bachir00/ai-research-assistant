"""
Int√©gration du syst√®me de m√©moire dans l'outil de recherche
"""

from langchain_core.tools import tool
from typing import Union
import asyncio

from src.agents.researcher_agent import ResearcherAgent
from src.agents.content_extractor_agent import ContentExtractorAgent
from src.agents.summarizer_agent import SummarizerAgent
from src.agents.global_synthesizer_agent import GlobalSynthesizerAgent

from src.models.research_models import ResearchQuery
# ------------ AGENTS ------------
researcher_agent = ResearcherAgent()
content_extractor_agent = ContentExtractorAgent()
summarizer_agent = SummarizerAgent()
global_synthesizer_agent = GlobalSynthesizerAgent()

# Importer le syst√®me de m√©moire
from .memory_integration import memory_system

# ============================================================================
# OUTIL AM√âLIOR√â AVEC M√âMOIRE
# ============================================================================

@tool
def research_complete_pipeline_with_memory(topic: str, max_results: Union[int, str] = 3, use_cache: bool = True) -> str:
    """Ex√©cute un pipeline de recherche complet avec syst√®me de m√©moire int√©gr√©.
    
    Ce tool intelligent :
    1. V√©rifie si des recherches similaires existent en cache
    2. Utilise la m√©moire vectorielle pour enrichir le contexte
    3. Ex√©cute le pipeline complet de recherche si n√©cessaire
    4. Stocke tous les r√©sultats pour r√©utilisation future
    5. D√©duplique automatiquement les documents
    
    Args:
        topic: Le sujet de recherche
        max_results: Nombre de sources √† analyser (2-10, d√©faut: 3)
        use_cache: Utiliser le cache si disponible (d√©faut: True)
    
    Returns:
        Un rapport complet enrichi par la m√©moire contextuelle
    """
    # Conversion et validation
    if isinstance(max_results, str):
        try:
            max_results = int(max_results)
        except ValueError:
            max_results = 3
    max_results = max(2, min(max_results, 10))
    
    async def run_pipeline_with_memory():
        print(f"\n{'='*60}")
        print(f"üöÄ PIPELINE DE RECHERCHE INTELLIGENT")
        print(f"üìã Sujet: {topic}")
        print(f"üíæ Cache activ√©: {use_cache}")
        print(f"{'='*60}\n")
        
        # ===== PHASE 1: R√âCUP√âRATION DU CONTEXTE =====
        print("üß† [Phase 1] R√©cup√©ration du contexte m√©moriel...")
        context = memory_system.retrieve_context_for_query(topic, use_cache=use_cache)
        
        # V√©rifier si on a un r√©sultat en cache
        if context['cached_result'] and use_cache:
            print("‚úÖ R√©sultat trouv√© en cache (< 24h)")
            print("üìä Utilisation du r√©sultat m√©moris√©")
            
            cached_report = context['cached_result']
            if hasattr(cached_report, 'final_report'):
                return cached_report.final_report.formatted_outputs.get('markdown', str(cached_report))
        
        # Afficher le contexte s√©mantique si disponible
        if context['semantic_context']:
            print(f"üìö Contexte s√©mantique r√©cup√©r√© ({len(context['semantic_context'])} caract√®res)")
        
        if context['related_topics']:
            print(f"üîó Topics similaires trouv√©s: {', '.join(context['related_topics'][:3])}")
        
        # ===== PHASE 2: EX√âCUTION DU PIPELINE =====
        print(f"\n{'='*60}")
        print("üî¨ [Phase 2] Ex√©cution du pipeline de recherche")
        print(f"{'='*60}\n")
        
        # √âTAPE 1: Recherche
        print("üîç [1/4] Recherche web en cours...")
        query = ResearchQuery(
            topic=topic,
            keywords=await researcher_agent.extract_keywords_with_llm(topic),
            max_results=max_results,
            search_depth="basic"
        )
        research_data = await researcher_agent.process(query)
        print(f"‚úÖ Trouv√© {research_data.total_found} sources")
        
        # √âTAPE 2: Extraction avec d√©duplication
        print("\nüìÑ [2/4] Extraction du contenu (avec d√©duplication)...")
        extraction_data = await content_extractor_agent.process_from_research_output(
            research_output=research_data
        )
        print(f"‚úÖ Extrait {extraction_data.successful_extractions} documents")
        
        # V√©rifier les doublons
        if extraction_data.documents:
            new_docs = []
            duplicates = 0
            for doc in extraction_data.documents:
                if not memory_system.vector_memory.is_duplicate(doc.content):
                    new_docs.append(doc)
                else:
                    duplicates += 1
            
            if duplicates > 0:
                print(f"‚ÑπÔ∏è {duplicates} documents en doublon ignor√©s")
                # Mettre √† jour extraction_data avec seulement les nouveaux docs
                extraction_data.documents = new_docs
        
        # √âTAPE 3: R√©sum√©s
        print("\nüìù [3/4] Cr√©ation des r√©sum√©s...")
        summarization_data = await summarizer_agent.process_from_extraction_result(
            extraction_result=extraction_data
        )
        print(f"‚úÖ G√©n√©r√© {summarization_data.total_documents} r√©sum√©s")
        
        # √âTAPE 4: Synth√®se globale enrichie
        print("\nüéØ [4/4] Synth√®se globale (enrichie par le contexte)...")
        
        # Enrichir avec le contexte s√©mantique si disponible
        if context['semantic_context']:
            print("üìö Enrichissement avec le contexte m√©moriel...")
        
        global_synthesis = await global_synthesizer_agent.process_from_summarization_output(
            summarization_output=summarization_data
        )
        print(f"‚úÖ Rapport final g√©n√©r√© ({global_synthesis.final_report.word_count} mots)")
        
        # ===== PHASE 3: STOCKAGE EN M√âMOIRE =====
        print(f"\n{'='*60}")
        print("üíæ [Phase 3] Stockage en m√©moire")
        print(f"{'='*60}\n")
        
        memory_system.process_research_result(
            topic=topic,
            extraction_result=extraction_data,
            summarization_result=summarization_data,
            global_synthesis=global_synthesis
        )
        
        # Ajouter √† l'historique des conversations
        final_report_text = global_synthesis.final_report.formatted_outputs.get('text', '')[:200]
        memory_system.agent_memory.add_conversation(
            user_message=f"Recherche sur: {topic}",
            assistant_response=final_report_text,
            metadata={'max_results': max_results, 'sources': research_data.total_found}
        )
        
        print(f"\n{'='*60}")
        print("‚ú® PIPELINE TERMIN√â AVEC SUCC√àS")
        print(f"üìä Statistiques:")
        print(f"   - Sources analys√©es: {research_data.total_found}")
        print(f"   - Documents stock√©s: {extraction_data.successful_extractions}")
        print(f"   - R√©sum√©s g√©n√©r√©s: {summarization_data.total_documents}")
        print(f"   - Mots du rapport: {global_synthesis.final_report.word_count}")
        print(f"{'='*60}\n")
        
        # Retourner le rapport en markdown
        return global_synthesis.final_report.formatted_outputs.get('markdown',
                                                                   global_synthesis.final_report.formatted_outputs.get('text',
                                                                                                                       str(global_synthesis)))
    
    return asyncio.run(run_pipeline_with_memory())


# ============================================================================
# OUTILS SUPPL√âMENTAIRES POUR LA GESTION DE M√âMOIRE
# ============================================================================

@tool
def search_in_memory(query: str, top_k: int = 5) -> str:
    """Recherche s√©mantique dans la m√©moire vectorielle.
    
    Utile pour retrouver des informations de recherches pr√©c√©dentes
    sans relancer une nouvelle recherche compl√®te.
    
    Args:
        query: Requ√™te de recherche
        top_k: Nombre de r√©sultats √† retourner
    
    Returns:
        Contexte pertinent trouv√© dans la m√©moire
    """
    print(f"üîç Recherche dans la m√©moire: '{query}'")
    
    results = memory_system.vector_memory.semantic_search(query, k=top_k)
    
    if not results:
        return "Aucun r√©sultat trouv√© dans la m√©moire."
    
    output = f"üìö {len(results)} r√©sultats trouv√©s dans la m√©moire:\n\n"
    
    for i, (doc, score) in enumerate(results, 1):
        output += f"[R√©sultat {i} - Pertinence: {score:.2%}]\n"
        output += f"Titre: {doc.metadata.get('title', 'N/A')}\n"
        output += f"Source: {doc.metadata.get('source', 'N/A')}\n"
        output += f"Contenu:\n{doc.page_content[:300]}...\n\n"
    
    return output


@tool
def get_research_history(n_last: int = 5) -> str:
    """R√©cup√®re l'historique des derni√®res recherches effectu√©es.
    
    Args:
        n_last: Nombre de conversations r√©centes √† retourner
    
    Returns:
        Historique format√© des recherches
    """
    print(f"üìú R√©cup√©ration des {n_last} derni√®res recherches...")
    
    history = list(memory_system.agent_memory.conversation_history)[-n_last:]
    
    if not history:
        return "Aucun historique de recherche disponible."
    
    output = f"üìö Historique des {len(history)} derni√®res recherches:\n\n"
    
    for i, conv in enumerate(history, 1):
        timestamp = conv.get('timestamp', 'N/A')
        user_msg = conv.get('user', '')[:100]
        metadata = conv.get('metadata', {})
        
        output += f"[Recherche {i}] - {timestamp}\n"
        output += f"Topic: {user_msg}\n"
        if metadata:
            output += f"D√©tails: {metadata}\n"
        output += "\n"
    
    return output


@tool
def clear_memory(confirm: bool = False) -> str:
    """R√©initialise compl√®tement le syst√®me de m√©moire.
    
    ‚ö†Ô∏è ATTENTION: Cette action est irr√©versible!
    
    Args:
        confirm: Doit √™tre True pour confirmer l'action
    
    Returns:
        Message de confirmation
    """
    if not confirm:
        return "‚ö†Ô∏è Action non confirm√©e. Passez confirm=True pour r√©initialiser la m√©moire."
    
    print("üóëÔ∏è R√©initialisation de la m√©moire...")
    memory_system.agent_memory.clear_all()
    
    # Note: On ne clear pas la base vectorielle car elle peut contenir des donn√©es pr√©cieuses
    # Si vraiment n√©cessaire, utiliser memory_system.vector_memory.collection.delete(where={})
    
    return "‚úÖ M√©moire de conversation r√©initialis√©e. Base vectorielle pr√©serv√©e."


# ============================================================================
# LISTE DES OUTILS MISE √Ä JOUR
# ============================================================================

# Mettre √† jour la liste des outils dans votre code principal
tools_with_memory = [
    research_complete_pipeline_with_memory,
    search_in_memory,
    get_research_history,
    clear_memory
]

print("‚úÖ Outils avec m√©moire initialis√©s:")
print("   1. research_complete_pipeline_with_memory - Pipeline complet avec cache")
print("   2. search_in_memory - Recherche dans la m√©moire vectorielle")
print("   3. get_research_history - Historique des recherches")
print("   4. clear_memory - R√©initialisation de la m√©moire")