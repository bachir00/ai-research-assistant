"""
Agent Researcher - Premier agent du pipeline.
Effectue la recherche web sur un sujet donn√© et retourne des sources pertinentes.
"""

from typing import List, Dict, Any, Optional
import asyncio
from datetime import datetime

from src.agents.base_agent import BaseAgent
from src.models.research_models import ResearchQuery, ResearchOutput, SearchResult
from src.models.state_models import AgentType
from src.services.search_api import SearchAPIManager, SearchAPIError
from src.services.llm_service import LLMService, LLMError
from src.core.logging import setup_logger
from config.prompts import RESEARCHER_PROMPT, SYSTEM_PROMPTS, KEYWORD_EXTRACTION_PROMPT


class ResearcherAgent(BaseAgent[ResearchQuery, ResearchOutput]):
    """
    Agent de recherche web.
    
    Responsabilit√©s:
    - Recevoir une requ√™te de recherche
    - Effectuer des recherches sur le web via des APIs
    - Analyser et filtrer les r√©sultats
    - Retourner une liste de sources pertinentes
    """
    
    def __init__(
        self,
        name: str = "researcher",
        max_retries: int = 3,
        timeout: float = 120.0  # 2 minutes pour la recherche
    ):
        super().__init__(
            agent_type=AgentType.RESEARCHER,
            name=name,
            max_retries=max_retries,
            timeout=timeout
        )
        
        # Initialisation du gestionnaire de recherche
        try:
            self.search_manager = SearchAPIManager()
            self.logger.info(f"APIs disponibles: {self.search_manager.get_available_apis()}")
        except Exception as e:
            self.logger.error(f"Impossible d'initialiser le gestionnaire de recherche: {e}")
            raise
        
        # Initialisation du service LLM pour l'extraction de mots-cl√©s
        try:
            self.llm_service = LLMService()
            self.logger.info("Service LLM initialis√© pour l'extraction de mots-cl√©s")
        except Exception as e:
            self.logger.error(f"Impossible d'initialiser le service LLM: {e}")
            raise
        
        # Configuration de recherche
        self.default_search_params = {
            "preferred_api": "tavily",
            "search_depth": "basic",
            "include_answer": True
        }
    
    def validate_input(self, input_data: ResearchQuery) -> bool:
        """
        Valide la requ√™te de recherche.
        
        Args:
            input_data: Requ√™te de recherche √† valider
            
        Returns:
            True si la requ√™te est valide
        """
        if not input_data.topic or len(input_data.topic.strip()) < 3:
            self.logger.error("Le sujet de recherche doit contenir au moins 3 caract√®res")
            return False
        
        if input_data.max_results <= 0 or input_data.max_results > 20:
            self.logger.error("Le nombre de r√©sultats doit √™tre entre 1 et 20")
            return False
        
        return True
    
    async def process(self, input_data: ResearchQuery) -> ResearchOutput:
        """
        Traite la requ√™te de recherche.
        
        Args:
            input_data: Requ√™te de recherche
            
        Returns:
            R√©sultats de recherche structur√©s
        """
        start_time = datetime.now()
        self.logger.info(f"D√©but de recherche pour: '{input_data.topic}'")
        
        # Pr√©paration de la requ√™te
        search_query = self._prepare_search_query(input_data)
        self.logger.info(f"Requ√™te pr√©par√©e: '{search_query}'")
        
        # Configuration des param√®tres de recherche
        search_params = {
            **self.default_search_params,
            "search_depth": input_data.search_depth,
            "max_results": input_data.max_results
        }
        
        try:
            # Recherche principale
            results = await self.search_manager.search(
                query=search_query,
                **search_params
            )
            
            # Post-traitement des r√©sultats
            filtered_results = self._filter_and_rank_results(
                results, 
                input_data.topic,
                input_data.keywords
            )
            
            # Limitation au nombre demand√©
            final_results = filtered_results[:input_data.max_results]
            
            # Calcul du temps de recherche
            search_time = (datetime.now() - start_time).total_seconds()
            
            # Cr√©ation de l'output
            research_output = ResearchOutput(
                query=input_data,
                results=final_results,
                total_found=len(results),
                search_time=search_time,
                search_engine=search_params["preferred_api"],
                timestamp=datetime.now()
            )
            
            self.logger.info(
                f"Recherche termin√©e: {len(final_results)} r√©sultats finaux "
                f"sur {len(results)} trouv√©s en {search_time:.2f}s"
            )
            
            return research_output
            
        except SearchAPIError as e:
            self.logger.error(f"Erreur de recherche: {e}")
            raise
        except Exception as e:
            self.logger.error(f"Erreur inattendue lors de la recherche: {e}")
            raise
    
    def _prepare_search_query(self, query: ResearchQuery) -> str:
        """
        Pr√©pare la requ√™te de recherche en optimisant les mots-cl√©s.
        
        Args:
            query: Requ√™te originale
            
        Returns:
            Requ√™te optimis√©e pour la recherche
        """
        # Commencer par le sujet principal
        search_terms = [query.topic]
        
        # Ajouter les mots-cl√©s s'ils existent
        if query.keywords:
            # √âviter la redondance avec le sujet principal
            unique_keywords = [
                kw for kw in query.keywords 
                if kw.lower() not in query.topic.lower()
            ]
            search_terms.extend(unique_keywords)
        
        # Joindre avec des espaces
        search_query = " ".join(search_terms)
        
        ##################### A Am√©liorer selon ce qu'on veut rechercher #################################
                 # Optimisations sp√©cifiques selon la profondeur 
        ##################################################################################################
        if query.search_depth == "advanced":
            # Pour les recherches avanc√©es, ajouter des termes de contexte
            if "intelligence artificielle" in search_query.lower() or "ia" in search_query.lower():
                search_query += " 2024 2025 r√©cent"
            if "emploi" in search_query.lower() or "travail" in search_query.lower():
                search_query += " march√© impact"
        
        return search_query.strip()
    
    def _filter_and_rank_results(
        self, 
        results: List[SearchResult], 
        topic: str,
        keywords: List[str]
    ) -> List[SearchResult]:
        """
        Filtre et classe les r√©sultats par pertinence.
        
        Args:
            results: R√©sultats bruts de la recherche
            topic: Sujet de recherche original
            keywords: Mots-cl√©s de recherche
            
        Returns:
            R√©sultats filtr√©s et class√©s
        """
        if not results:
            return []
        
        # Mots-cl√©s pour le scoring (topic + keywords)
        scoring_terms = [topic.lower()] + [kw.lower() for kw in keywords]
        
        # Calcul du score de pertinence pour chaque r√©sultat
        scored_results = []
        for result in results:
            score = self._calculate_relevance_score(result, scoring_terms)
            
            # Mise √† jour du score dans le r√©sultat
            result.score = score
            scored_results.append(result)
        
        # Tri par score d√©croissant
        scored_results.sort(key=lambda x: x.score or 0, reverse=True)
        
        # Filtrage des r√©sultats de faible qualit√©
        min_score = 0.1  # Score minimum acceptable
        filtered_results = [r for r in scored_results if (r.score or 0) >= min_score]
        
        self.logger.info(f"Filtrage: {len(filtered_results)} r√©sultats conserv√©s sur {len(results)}")
        
        return filtered_results
    
    #Am√©iorer le score selon le site 
    # EX: if result.url.endswith(".edu") or result.url.endswith(".gov"):
    # score += 0.1
    def _calculate_relevance_score(
        self, 
        result: SearchResult, 
        scoring_terms: List[str]
    ) -> float:
        """
        Calcule un score de pertinence pour un r√©sultat.
        
        Args:
            result: R√©sultat √† scorer
            scoring_terms: Termes de r√©f√©rence pour le scoring
            
        Returns:
            Score entre 0 et 1
        """
        score = 0.0
        
        # Texte √† analyser (titre + snippet)
        text_to_analyze = f"{result.title} {result.snippet}".lower()
        
        # Score bas√© sur la pr√©sence des termes de recherche
        term_matches = 0
        for term in scoring_terms:
            if term in text_to_analyze:
                term_matches += 1
        
        if scoring_terms:
            term_score = term_matches / len(scoring_terms)
            score += term_score * 0.6  # 60% du score
        
        # Bonus pour les titres pertinents
        title_matches = sum(1 for term in scoring_terms if term in result.title.lower())
        if scoring_terms:
            title_score = title_matches / len(scoring_terms)
            score += title_score * 0.3  # 30% du score
        
        # Bonus pour les sources r√©centes (si date disponible)
        if result.published_date:
            days_old = (datetime.now() - result.published_date.replace(tzinfo=None)).days
            if days_old <= 365:  # Moins d'un an
                recency_score = max(0, 1 - (days_old / 365))
                score += recency_score * 0.1  # 10% du score
        
        # Score existant de l'API (si disponible)
        if result.score and result.score > 0:
            score = (score + result.score) / 2  # Moyenne avec le score API
        
        return min(score, 1.0)  # Cap √† 1.0
    
    async def extract_keywords_with_llm(self, topic: str) -> List[str]:
        """
        Extrait automatiquement des mots-cl√©s pertinents √† partir du sujet
        en utilisant le service LLM.
        
        Args:
            topic: Sujet de recherche
            
        Returns:
            Liste de mots-cl√©s extraits
        """
        try:
            self.logger.info(f"Extraction de mots-cl√©s pour: '{topic}'")
            
            # Pr√©paration du prompt avec le template
            prompt = KEYWORD_EXTRACTION_PROMPT.format(topic=topic)
            
            # Appel au service LLM
            response = await self.llm_service.generate_completion(
                prompt=prompt,
                system_prompt="Tu es un expert en analyse s√©mantique sp√©cialis√© dans l'extraction de mots-cl√©s pour la recherche web.",
                temperature=0.3,  # Faible temp√©rature pour plus de coh√©rence
                max_tokens=150    # Limite pour les mots-cl√©s
            )
            
            # Parsing de la r√©ponse
            keywords = self._parse_keywords_response(response)
            
            self.logger.info(f"Mots-cl√©s extraits: {keywords}")
            return keywords
            
        except LLMError as e:
            self.logger.error(f"Erreur LLM lors de l'extraction de mots-cl√©s: {e}")
            # Fallback: extraction simple bas√©e sur le sujet
            return self._extract_keywords_fallback(topic)
        except Exception as e:
            self.logger.error(f"Erreur inattendue lors de l'extraction de mots-cl√©s: {e}")
            return self._extract_keywords_fallback(topic)
    
    def _parse_keywords_response(self, response: str) -> List[str]:
        """
        Parse la r√©ponse du LLM pour extraire les mots-cl√©s.
        
        Args:
            response: R√©ponse brute du LLM
            
        Returns:
            Liste de mots-cl√©s nettoy√©s
        """
        # Nettoyer la r√©ponse
        response = response.strip()
        
        # Supprimer les pr√©fixes potentiels
        for prefix in ["mots-cl√©s:", "keywords:", "r√©ponse:", "voici:", "liste:"]:
            if response.lower().startswith(prefix):
                response = response[len(prefix):].strip()
        
        # S√©parer par virgules
        keywords = [kw.strip() for kw in response.split(",")]
        
        # Nettoyer et filtrer
        cleaned_keywords = []
        for kw in keywords:
            # Supprimer les num√©ros et tirets
            kw = kw.strip("0123456789.-\t\n ")
            
            # Filtrer les mots trop courts ou vides
            if len(kw) >= 2 and kw.lower() not in ["et", "ou", "le", "la", "les", "de", "du", "des"]:
                cleaned_keywords.append(kw)
        
        # Limiter le nombre de mots-cl√©s
        return cleaned_keywords[:7]
    
    def _extract_keywords_fallback(self, topic: str) -> List[str]:
        """
        M√©thode de fallback pour extraire des mots-cl√©s simples.
        
        Args:
            topic: Sujet de recherche
            
        Returns:
            Liste de mots-cl√©s basiques
        """
        self.logger.info("Utilisation du fallback pour l'extraction de mots-cl√©s")
        
        # Mots communs √† ignorer
        stop_words = {
            "le", "la", "les", "de", "du", "des", "et", "ou", "sur", "dans", 
            "avec", "pour", "par", "en", "√†", "un", "une", "ce", "cette", "ces"
        }
        
        # Extraction simple bas√©e sur les mots significatifs
        words = topic.lower().split()
        keywords = [word for word in words if len(word) >= 3 and word not in stop_words]
        
        return keywords[:5]  # Limiter √† 5 mots-cl√©s max
    
    async def search_with_fallback(
        self, 
        query: str, 
        max_results: int = 5
    ) -> List[SearchResult]:
        """
        M√©thode utilitaire pour recherche simple avec fallback.
        
        Args:
            query: Requ√™te de recherche simple
            max_results: Nombre de r√©sultats souhait√©s
            
        Returns:
            Liste des r√©sultats
        """
        research_query = ResearchQuery(
            topic=query,
            max_results=max_results
        )
        
        output = await self.process(research_query)
        return output.results
    
    def get_search_stats(self) -> Dict[str, Any]:
        """
        Retourne les statistiques de recherche de l'agent.
        
        Returns:
            Dictionnaire avec les statistiques
        """
        base_stats = self.get_status()
        search_stats = {
            "available_apis": self.search_manager.get_available_apis(),
            "search_params": self.default_search_params
        }
        
        return {**base_stats, **search_stats}
    

# Fonctions utilitaires pour la sauvegarde
def save_research_output(output: ResearchOutput, filename: str = None) -> str:
    """
    Sauvegarde un ResearchOutput dans un fichier JSON.
    
    Args:
        output: Sortie de recherche √† sauvegarder
        filename: Nom du fichier (optionnel)
        
    Returns:
        Nom du fichier sauvegard√©
    """
    import json
    from datetime import datetime
    
    if not filename:
        # G√©n√©rer un nom de fichier bas√© sur le sujet et timestamp
        clean_topic = "".join(c for c in output.query.topic if c.isalnum() or c in (' ', '-', '_')).rstrip()
        clean_topic = clean_topic.replace(' ', '_')[:30]
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"research_output_{clean_topic}_{timestamp}.json"
    
    try:
        # Conversion en dictionnaire avec s√©rialisation des dates
        output_dict = output.model_dump(mode='json')
        
        # Sauvegarde dans le fichier
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(output_dict, f, indent=2, ensure_ascii=False)
        
        return filename
        
    except Exception as e:
        raise Exception(f"Erreur lors de la sauvegarde: {e}")


def load_research_output(filename: str) -> ResearchOutput:
    """
    Charge un ResearchOutput depuis un fichier JSON.
    
    Args:
        filename: Nom du fichier √† charger
        
    Returns:
        ResearchOutput charg√©
    """
    import json
    
    try:
        with open(filename, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        # Reconstruction du ResearchOutput
        return ResearchOutput(**data)
        
    except Exception as e:
        raise Exception(f"Erreur lors du chargement: {e}")


# Ecrire un main pour tester ici la classe
if __name__ == "__main__":
    import asyncio
    import json
    from datetime import datetime
    from src.core.logging import setup_logger
    logger = setup_logger("researcher_agent_test")
    
    async def main():
        agent = ResearcherAgent()
        
        # Test 1: Extraction automatique de mots-cl√©s avec LLM
        topic = "impact de l'intelligence artificielle sur le march√© de l'emploi"
        logger.info(f"=== Test d'extraction de mots-cl√©s pour: {topic} ===")
        
        try:
            # Extraction automatique des mots-cl√©s
            keywords = await agent.extract_keywords_with_llm(topic)
            logger.info(f"Mots-cl√©s extraits automatiquement: {keywords}")
            
            # Cr√©ation de la requ√™te avec les mots-cl√©s extraits
            query = ResearchQuery(
                topic=topic,
                keywords=keywords,  # Utilisation des mots-cl√©s extraits automatiquement
                max_results=2,
                search_depth="basic"
            )   
            
            if agent.validate_input(query):
                logger.info("=== D√©but de la recherche avec mots-cl√©s automatiques ===")
                output = await agent.process(query)
                logger.info(f"R√©sultats obtenus: {len(output.results)}")
                
                # Affichage des r√©sultats
                for i, res in enumerate(output.results, 1):
                    logger.info(f"{i}. {res.title}")
                    logger.info(f"   URL: {res.url}")
                    logger.info(f"   Score: {res.score:.3f}")
                    logger.info(f"   Snippet: {res.snippet[:100]}...")
                    logger.info("")
                
                # === SAUVEGARDE DU RESEARCHOUTPUT ===
                logger.info("=== Sauvegarde du ResearchOutput ===")
                
                try:
                    filename = save_research_output(output)
                    logger.info(f"‚úÖ ResearchOutput sauvegard√© dans: {filename}")
                    
                    # Affichage du contenu sauvegard√©
                    logger.info("üìÑ Contenu sauvegard√©:")
                    logger.info(f"  ‚Ä¢ Sujet: {output.query.topic}")
                    logger.info(f"  ‚Ä¢ Mots-cl√©s: {output.query.keywords}")
                    logger.info(f"  ‚Ä¢ Nombre de r√©sultats: {len(output.results)}")
                    logger.info(f"  ‚Ä¢ Temps de recherche: {output.search_time:.2f}s")
                    logger.info(f"  ‚Ä¢ Moteur utilis√©: {output.search_engine}")
                    logger.info(f"  ‚Ä¢ Timestamp: {output.timestamp}")
                    
                    # Test de chargement pour v√©rifier l'int√©grit√©
                    logger.info("=== Test de chargement ===")
                    loaded_output = load_research_output(filename)
                    logger.info(f"‚úÖ ResearchOutput recharg√© avec succ√®s")
                    logger.info(f"  ‚Ä¢ V√©rification: {len(loaded_output.results)} r√©sultats charg√©s")
                    
                    # Comparaison des donn√©es
                    if loaded_output.query.topic == output.query.topic:
                        logger.info("‚úÖ Int√©grit√© des donn√©es v√©rifi√©e")
                    else:
                        logger.error("‚ùå Erreur d'int√©grit√© des donn√©es")
                    
                    # Affichage du format JSON pour r√©f√©rence
                    logger.info("\nüìã EXEMPLE DE FORMAT JSON SAUVEGARD√â:")
                    logger.info("-" * 50)
                    
                    # Cr√©er un exemple compact pour l'affichage
                    example_output = {
                        "query": {
                            "topic": output.query.topic,
                            "keywords": output.query.keywords[:3],  # Limiter pour l'affichage
                            "max_results": output.query.max_results,
                            "search_depth": output.query.search_depth
                        },
                        "results": [
                            {
                                "title": res.title,
                                "url": str(res.url),
                                "snippet": res.snippet[:100] + "...",
                                "score": res.score
                            } for res in output.results[:2]  # Limiter √† 2 r√©sultats pour l'affichage
                        ],
                        "total_found": output.total_found,
                        "search_time": output.search_time,
                        "search_engine": output.search_engine,
                        "timestamp": output.timestamp.isoformat()
                    }
                    
                    print(json.dumps(example_output, indent=2, ensure_ascii=False))
                    
                except Exception as save_error:
                    logger.error(f"‚ùå Erreur lors de la sauvegarde: {save_error}")
                
            else:
                logger.error("Requ√™te invalide.")
                
        except Exception as e:
            logger.error(f"Erreur lors du test: {e}")
    
    # Fonction utilitaire pour tester la sauvegarde ind√©pendamment
    async def test_save_load():
        """Test sp√©cifique de sauvegarde/chargement."""
        logger.info("=== TEST SAUVEGARDE/CHARGEMENT SEUL ===")
        
        # Cr√©er un ResearchOutput factice pour le test
        from datetime import datetime
        
        fake_results = [
            SearchResult(
                title="Test Article 1",
                url="https://example.com/test1",
                snippet="Ceci est un test de snippet pour l'article 1",
                score=0.85
            ),
            SearchResult(
                title="Test Article 2", 
                url="https://example.com/test2",
                snippet="Ceci est un test de snippet pour l'article 2",
                score=0.78
            )
        ]
        
        fake_query = ResearchQuery(
            topic="test sauvegarde",
            keywords=["test", "sauvegarde", "json"],
            max_results=2
        )
        
        fake_output = ResearchOutput(
            query=fake_query,
            results=fake_results,
            total_found=2,
            search_time=1.5,
            search_engine="test",
            timestamp=datetime.now()
        )
        
        try:
            # Test de sauvegarde
            filename = save_research_output(fake_output, "test_research_output.json")
            logger.info(f"‚úÖ Test sauvegarde r√©ussi: {filename}")
            
            # Test de chargement
            loaded = load_research_output(filename)
            logger.info(f"‚úÖ Test chargement r√©ussi: {len(loaded.results)} r√©sultats")
            
        except Exception as e:
            logger.error(f"‚ùå Test sauvegarde/chargement √©chou√©: {e}")
    
    # Choix du test √† ex√©cuter
    import sys
    if len(sys.argv) > 1 and sys.argv[1] == "--test-save":
        asyncio.run(test_save_load())
    else:
        asyncio.run(main())